------------------------------------------------
------------------------------------------------
Curso Docker Platzi
------------------------------------------------
------------------------------------------------

Docker
  Estandar para desarrollar, distribuir y ejecutar aplicaciones a nivel productivo

Por que?
  compatibilidad del software en los ambientes de desarrollo y produccion
  genera confianza, desplegar en otros entornos
  

*** LAS TRES AREAS EN EL DESARROLLO DE SOFTWARE PROFESIONAL ***
  
  1. construir
  
    escribir codigo es una pequeña parte
    los problemas complejos necesitan equipos
      --> entornos de desarrollo
      --> dependencias
      --> entonrno de ejecucion
      --> equivalenias con entorno productivo
      --> servicios externos
    
  2. distribuir
  
    tu codigo tiene que transformarse en un artefacto o varios que puedan ser transformados
    a donde tenga que ser ejecutados
      --> divergencia de repositorios
      --> divergencia de artefactos
      --> versionado
      
  3. ejecutar
  
    la maquina donde se escribe el softare siempre es distinta a la maquina donde se ejecuta de manera productiva
      --> compatibilidad con el entorno productivo
      --> dependencias
      --> disponibilidad de servicios externos
      --> recursos de hardware
 

Aportes de la clase

Resumen de la clase:

“Docker te permite construir, distribuir y ejecutar cualquier aplicación en cualquier lado.”

Problemáticas del desarrollo de software
1. Construir - Escribir código en la máquina del desarrollador. (Compile, que no compile, arreglar el bug, compartir código, etc. )

Problemática:
  Entorno de desarrollo (paquetes)
  Dependencias (Frameworks, bibliotecas)
  Versiones de entornos de ejecución (runtime, versión Node)
  Equivalencia de entornos de desarrollo (compartir el código)
  Equivalencia con entornos productivos (pasar a producción)
  Servicios externos (integración con otros servicios ejem: base de datos)
  
2. Distribuir - Llevar la aplicación donde se va a desplegar (Transformarse en un artefacto)

Problemática:
  Output de build heterogeo (múltiples compilaciones)
  Acceso a servidores productivos (No tenemos acceso al servidor)
  Ejecución nativa vs virtualizada
  Entornos Serverless

3. Ejecutar - Implementar la solución en el ambiente de producción (Subir a producción)
  El reto Hacer que funcione como debería funcionar

Problemática:
  Dependencia de aplicación (paquetes, runtime)
  Compatibilidad con el entorno productivo (sistema operativo poco amigable con la solución)
  Disponibilidad de servicios externos (Acceso a los servicios externos)
  Recursos de hardware (Capacidad de ejecución - Menos memoria, procesador más debil)
      


***  VIRTUALIZACION ***

version virtual de algun recurso tecnologico como (...) hardware, un sistema operativo, un dispositivo de almacenamiento o recurso de red
  
  permite atacar en simulateno os tres problemas del desarrollo de software profesional

Maquinas virtuales

  Problemas de las VMs
  
    Peso
      --> en el orden de los GB repiten archivos comunes, inicio lento

    Costos de administracion
      --> necesita mantenimiento igual que cualquier otra computadora
      
    Multiples de formatos
      --> VDI, VMDK, VHD, raw entre otras
      
para solucionar el tema de las maquinas virtuales se crearon los Contenedores

  Objetivo
    el empleo de contenedores para contruir y desplegar software
      --> flexibles
      --> livianos
      --> portables
      --> Bajo acoplamiento
      --> Escalables
      --> Seguros
  
Aporte de la clase

Un contenedor la unidad logica mas importande de docker que permite encapsular las dependencias de un proyecto en un entorno aislado, 
y pasársela a tus compañeros o colocarlo en un servidor para el despliegue de manera fácil.

¡Alerta! Puedes ver a un contendor como una maquina virtual pero eso no significa que lo sea, una maquina virtual puede llegar a se muy similar debido a sus funcionalidades 
como el aislamiento de procesos.

Entonces… ¿cuál es el beneficio de usar contenedores en lugar de maquinas virtuales?

El mayor beneficio es que los contenedores de Docker están en el nivel de los MB eso nos da ventajas en el consumo de recursos, ya que estos corren compartiendo el host del 
kernel de Linux, por otro lado las maquinas virtuales son un sistema operativo(O.S) con sus propias apps que corre sobre el tuyo usando virtualizacion y que consume muchos 
recursos en el nivel de los GB. Una mejor forma de ver esto es observando la arquitectura de los contendores y de las maquinas virtuales



*** PREPARANDO TU ENTORNO DE TRABAJO ***

pagina web --> docker.com
  Doccker desktop
  Docker Hub
  Play with Docker
  
para maquinas windows menores a 10
  --> https://github.com/docker/toolbox/releases
windows 10
  --> 
  
aportes de la clase

Puedes seguir las guías de instalación de docker en linux dependiendo de tu distribución.
  Cent OS: https://docs.docker.com/engine/install/centos/
  Debian: https://docs.docker.com/engine/install/debian/
  Fedora: https://docs.docker.com/engine/install/fedora/
  Ubuntu: https://docs.docker.com/engine/install/ubuntu/



*** PRIMEROS PASOS DE CONTENEDOR - HOLA MUNDO ***

--> comando
  docker run <nombre del contenedor a crear>
    --> ejemplo docker run hello-world

aportes de la clase

- Levantando contenedores
🔹 Arrancar un contenedor.

docker run <image_container>
Ejemplo:

docker run hello-world
🔹 Arrancar un contenedor asignándole un nombre.

docker run --name <name_container> <image_container>
Ejemplo:

docker run --name contenedor_test ubuntu
🔹 Arrancar un contenedor con una terminal interactiva. Pasándole una shell para acceder al contenedor.

docker run -it <image_container> <shell>
Ejemplo:

docker run -it ubuntu bash
🔹 Arrancar un contenedor. Mapeando un puerto del host a un puerto del contenedor.

puerto_host : puerto_contenedor
docker run -p <host_port>:<container_port> <image_container>
Ejemplo:

docker run -p 8080:80 nginx
Igual que el ejemplo anterior pero dejándolo en segundo plano.

docker run -p 8080:80 -d nginx
🔹 Arrancar un contenedor. Que tras terminar su periodo de vida. Será eliminado automáticamente.

docker run --rm <image_container>
Ejemplo:

docker run -p 8080:80 -d --rm nginx
🔹 Arrancar un contenedor con un volume.

docker run -v <volume_name>:<mount_point>:<options> <image_container>
Ejemplo:

Volume -> test
Punto de montaje en el contenedor -> /apps
Opciones -> rw (Lectura y escritura)
docker run -v test:/apps:rw nginx
🔹 Arrancar un contenedor con un bind mount.

docker run -v <shared_folder>:<mount_point>:<options> <image_container>
Ejemplo:

Ruta del host a compartir -> /home/application
Punto de montaje en el contenedor -> /apps
Opciones -> ro (Solo lectura)
docker run -v /home/application:/apps:ro ubuntu
🔹 Arrancar un contenedor con tmpfs.

docker run \
--mount type=tmpfs,destination=<mount_point>,tmpfs-mode=<permisos>,tmpfs-size=<bytes_size> \
<image_container>
Ejemplo:

Punto de montaje en el contenedor -> /temporal
Permisos -> Todos los permisos solo para el propietario.
Tamaño del FS -> 21474836480 bytes = 20G
docker run \
--mount type=tmpfs,destination=/temporal,tmpfs-mode=700,tmpfs-size=21474836480 \
nginx
- Listando contenedores
🔹 Lista de los contenedores activos.

docker ps
🔹 Lista de todos los contenedores activos e inactivos del sistema.

docker ps -a
🔹 Lista los ID de todos los contenedores.

docker ps -aq
- Debugging
🔹 Inspeccionar la data de un contenedor.

Por su ID:
docker inspect <id_container>
Por su nombre:
docker inspect <name_container>
Aplicando filtros. Por ejemplo buscando las variables de entorno:
docker inspect -f '{{ json .Config.Env }}' <name_container>
🔹 Ver los logs del contenedor.

docker logs <name_container>
- Eliminando contenedores
🔹 Eliminar un contenedor que no este arriba.

Se puede hacer tanto por nombre como por ID.
docker rm <name_container>
🔹 Eliminar un contenedor aunque este arriba. Forzándolo.

Se puede hacer tanto por nombre como por ID.
docker rm -f <id_container>
🔹 Eliminar todos los contenedores que no esten arriba a la vez.

docker rm $(docker ps -aq)
   


*** CONCEPTO FUNDAMENTALES DE DOCKER - CONTENEDORES ***

Docker es una herramienta de codigo abierto que nos sirve para desarrollar, enviar y ejecutar
aplicaciones en contenedores

que son los contenedores?
  son unidades logicas computadas por un conjunto de procesos
  los contenedores surgieron con la union de varias tecnologias como
    namespaces
    cgroups
    chroot

Docker por dentro

mediante el cliente podremos enviar comandos al docker deamon para interactuar con los contenedors
  docker deamon recibe los comandos y envia ordenes a los contenedores para indicarles como y que deben ejecutar

contenedores
  ejecutan los proceso indicados por el docker deamon
  estos procesos viven en el contenedor y mueren con el contenedor, esto hace que se mantengan
  asilados de los proceso que se mantengan aislados de los procesos que corren en el sistma operativo del host

aunque puedes usar Docker tanto en windows como MacOs. este solo corre nativamente en Linux


Por que usar Docker?

  "en mi equipo la app corria correctamente"
  evita fallos gracias a que podras tener entornos de desarrollo y de produccion practicamente iguales
  
  "Evita problemas con las versiones"
  en cada contenedor podras correr lo que necesites
  
  "Distribuye y comparte facilmente"
  una de las grandes ventajas de los contenedores es su pequeño tamaño. imagina tener un Linuz en tan solo 5MB con Docker es posible
  

Que es un contenedor ?

  Es una agrupación de procesos.
  Es una entidad lógica, no tiene el limite estricto de las máquinas virtuales, emulación del sistema operativo simulado por otra más abajo.
  Ejecuta sus procesos de forma nativa.
  Los procesos que se ejecutan adentro de los contenedores ven su universo como el contenedor lo define, no pueden ver mas allá del contenedor, a pesar de estar corriendo en una maquina más grande.
  No tienen forma de consumir más recursos que los que se les permite. Si esta restringido en memoria ram por ejemplo, es la única que pueden usar.
  A fines prácticos los podemos imaginar cómo maquinas virtuales, pero NO lo son. Máquinas virtuales livianas.
  Docker corre de forma nativa solo en Linux.
  Sector del disco: Cuando un contenedor es ejecutado, el daemon de docker le dice, a partir de acá para arriba este disco es tuyo, pero no puedes subir mas arriba.
  Docker hace que los procesos adentro de un contenedor este aislados del resto del sistema, no le permite ver más allá.
  Cada contenedor tiene un ID único, también tiene un nombre.



*** COMPRENDIENDO DOCKER ***

Comandos:

  $ docker run hello-world (corro el contenedor hello-world)
  $ docker ps (muestra los contenedores activos)
  $ docker ps -a (muestra todos los contenedores)
  $ docker inspect <containe ID> (muestra el detalle completo de un contenedor)
  $ docker inspect <name> (igual que el anterior pero invocado con el nombre)
  $ docker run –-name hello-platzi hello-world (le asigno un nombre custom “hello-platzi”)
  $ docker rename hello-platzi hola-platzy (cambio el nombre de hello-platzi a hola-platzi)
  $ docker rm <ID o nombre> (borro un contenedor)
  $ docker container prune (borro todos lo contenedores que esten parados)



*** EL MODO INTERACTIVO - CORRER UN LINUX UBUNTU CON DOCKER  ***

comando
--> docker run ubuntu
--> docker run -it ubuntu  (el comando it significa iterativo, podemos entrar a la maquina de ubuntu y navegar entre sus archivos)

Comandos:
$ docker run ubuntu (corre un ubuntu pero lo deja apagado)
$ docker ps -a (lista todos los contenedores)
$ docker -it ubuntu (lo corre y entro al shell de ubuntu)
-i: interactivo
-t: abre la consola
  --> cat /etc/lsb-release (veo la versión de Linux)


With an Existing container

1. start the container
    --> docker start id-container
2. execute interactively bash in the container
    --> docker exec -it id-container bash 



*** CICLO DE VIDA DE UN CONTENEDOR  ***

comando
  --> $ docker run --name alwaysup -d ubuntu tail -f /dev/null
  
  observaciones
    se pueden usar al final del tail -f las siguientes instrucciones para que no se apague el contenedor
      /dev/full
      /dev/zero
      /dev/random
      
  --> $ docker exec -it alwaysup bash
  
  --> $ docker inspect --format '{{.State.Pid}}' alwaysup
      --> 3744
      --> $ kill 3744
          bash: kill: (3744) - No such process (no corre en windows)
      
          Para detener procesos en windows usamos el siguiente comando
          --> $ docker stop alwaysup



***  EXPONIENDO CONTENEDORES ***

Comandos:

$ docker run -d --name proxy nginx (corro un nginx)
$ docker stop proxy (apaga el contenedor)
$ docker rm proxy (borro el contenedor)
$ docker rm -f <contenedor> (lo para y lo borra)

$ docker run -d --name proxy -p 8080:80 nginx (corro un nginx y expongo el puerto 80 del contenedor en el puerto 8080 de mi máquina)
  --> docker run -d --name [name] -p [HostPort/8080]:[ContainerPort/80] [imagen/nginx]

localhost:8080 (desde mi navegador compruebo que funcione)
$ docker logs proxy (veo los logs)
$ docker logs -f proxy (hago un follow del log)
$ docker logs --tail 10 -f proxy (veo y sigo solo las 10 últimas entradas del log)



*** BIND MOUNTS  ***

Todo lo que se ve en esta clase está relacionado con volúmenes y como ya se dijo en clases anteriores Docker es virtualización de sistemas encontramos 
también volúmenes que son algo así como discos duros o datos que los contenedores pueden usar

Hay varios tipos de volúmenes

--> Container --> (bind mount)  --> filesystem 
              --> (Volume)      --> [docker area] 
              --> tmpfs mount   ----------------------> Memory

Para diferentes usos pero siempre se usan para persistir datos como por ejemplo imagina que estás haciendo una app que usa postgres sin importar 
la tecnología que usas para la lógica (node, python, php, java, c#) puedes tener muchas instancias de postgres en muchas versiones y los datos no se perderán 
a menos que los elimines

--> https://docs.docker.com/storage/volumes/

Para W10
usaré este tutorial para lo que me comentaste sobre WSL2:
https://platzi.com/tutoriales/1650-prework/5895-aprende-a-instalar-wsl-2-de-la-manera-sencilla/
y luego haré lo que me comentas 😃

Comandos:

$ mkdir dockerdata (creo un directorio en mi máquina)
$ docker run -d --name db mongo
$ docker ps (veo los contenedores activos)
$ docker exec -it db bash (entro al bash del contenedor)
$ mongo (me conecto a la BBDD)

    shows dbs (listo las BBDD)
    use platzi ( creo la BBDD platzi)
    db.users.insert({"nombre":"walther"}) (inserto un nuevo dato)
    db.users.find() (veo el dato que cargué)
    $ docker run -d --name db -v <path de mi maquina>:<path dentro del contenedor(/data/db mongo)> (corro un contenedor de mongo y creo un bind mount)



*** VOLUMENES  ***

Manera mas estandar en manejar la informacion de los dockers
Fueron una evolucion para manejar datos, 
mejora la seguridad de la informacion cuando se guarda los datos en disco
solo los volumenes pueden acceder a los datos creados desde esta opcion
por bind-mount cualquiera con acceso al disco podria manipular los datos

Comandos volumenes

--> docker volume ls (lista todos los volumenes creados)
--> docker volume create [nombre de la bd]
--> docker run -d --name db --mount src=dbdata,dst=/data/db mongo (ruta destino donde mongo db guarda su bd)



*** INSERTS Y EXTRAER ARCHIVOS DE UN CONTENEDOR  ***

Comandos:

$ touch prueba.txt (creo un archivo en mi máquina)
$ docker run -d --name copytest ubuntu tail -f /dev/null (corron un ubuntu y le agrego el tail para que quede activo)
$ docker exec -it copytest bash (entro al contenedor)
$ mkdir testing (creo un directorio en el contenedor)
$ docker cp prueba.txt copytest:/testing/test.txt (copio el archivo dentro del contenedor)
$ docker cp copytest:/testing localtesting (copio el directorio de un contenedor a mi máquina)
con "docker cp" no hace falta que el contenedor esté corriendo

HOST

  Container   -->   Bind mount    --> Filesystem 
              ----------------------> [Docker Area]   
              ----- tmpts mount -----------------------> Memory

Host        --> Donde Docker esta instalado
Bind Mount  --> Guarda los archivos en la maquina local persistiendoy visualizando estos datos (No seguro)
Volumen     --> Guarda los archivos en el area de Docker donde Docker los administra (Seguro) 
TMPFS Mount --> Guarda los archivos temporales y persisten los datos en la memoria del contenedor, cuando muera sus datos mueren con el contenedor


Acerca de el comando tail
-------------------------
Por default, éste comando imprime las últimas 10 líneas de un archivo en el sistema operativo GNU/Linux y luego termina.
al pasarle -f, indicamos que se “vigilen” los cambios en el archivo que le pasemos.

Acerca de /dev/null

Se le conoce como una “caja negra” que no contiene ni hace nada.
para entender mejor el uso de éste fichero podemos analizar los siguientes casos:
Si ejecutamos el comando

- -> cat /dev/null

No se producirá salida o mensaje

Por lo cual es normalmente utilizado para recibir archivos basura (descartables), o para vaciar archivos mediante redirección:

  --> ls > /dev/null

Manda la lista de archivos de ls a el archivo /dev/null, con lo cual dicha lista desaparece.

Si ejecutamos la siguiente orden:

  --> cat /dev/null  > Archivo.Awk

Estaríamos borrando el contenido de Archivo.Awk, es decir, dejándolo vacío.

Como nota final, cabe aclarar que no es posible copiar o mover archivos hacia /dev/null

Práctica realizada:

Para crear un archivo en mi máquina:

  --> touch prueba.txt

Crear un contenedor llamado copytest, que corra ubuntu e iniciar un proceso que se mantenga activo:

  --> docker run -d --name copytest ubuntu tail -f /dev/null

Iniciar una conexión de terminal con el contenedor que está corriendo ubuntu

docker exec -it copytest bash

Creamos un directorio llamado testing en el contenedor de ubuntu

  --> mkdir testing

Comando docker para copiar un fichero o un directorio desde la máquina anfitrión hacia el contenedor, copytest es el nombre del contenedor hacia el cual queremos copiar el archivo

  --> docker cp prueba.txt copytest:/testing/test.txt

Comando para ejecutar la acción inversa, es decir, copiar fichero o directorio desde el contenedor hacia la máquina anfitrión.
donde localtesting será el nombre de un nuevo directorio que se creará en la máquina anfitrión dentro del directorio en el que nos encontremos al momento de haber ejecutado el siguiente comando:

  -->  docker cp copytest:/testing localtesting 

Nota: utilizando docker cp, no es necesario que el contenedor esté corriendo



*** CONCEPTOS FUNDAMENTALES DE DOCKER: IMAGENES  ***


las imagenes son como Docker intenta solucionar el tema de cosntruccion y distribucion de software
plantillas o modles de las cuales docker crea contenedores
empaquetados para que docker pueda ejecutarse
  --> configuracion
  --> librerias
  --> archivos

Comandos:

  --> docker image ls (veo las imágenes que tengo localmente)
  --> docker images -a (veo las imagenes instaladas)
  --> docker pull <image_name>:<tag_version>
      ejemplo:  docker pull ubuntu:20.04 (bajo la imagen de ubuntu con una versión específica)
  
  
  
  *** CONTRUYENDO UNA IMAGEN PROPIA ***
  
 cada imagen es un conjunto de capas
 
  Comandos:

--> mkdir imagenes (creo un directorio en mi máquina)
--> cd imagenes (entro al directorio)
--> touch Dockerfile (creo un Dockerfile)
--> code . (abro code en el direcotrio en el que estoy)

##Contenido del Dockerfile##
FROM ubuntu:latest
RUN touch /ust/src/hola-platzi.txt (comando a ejecutar en tiempo de build)
##fin##

--> docker build -t ubuntu:platzi . (creo una imagen con el contexto de build <directorio>)
--> docker run -it ubuntu:platzi (corro el contenedor con la nueva imagen)
--> docker login (me logueo en docker hub)
--> docker tag ubuntu:platzi miusuario/ubuntu:platzy (cambio el tag para poder subirla a mi docker hub)
--> docker push miusuario/ubuntu:platzi (publico la imagen a mi docker hub)



*** EL SISTEMA DE CAPAS ***

Comandos:

--> docker history ubuntu:platzi (veo la info de como se construyó cada capa)

el comando anterior no es muy comoda para revisar las configuraciones, para 
esto es la el comando siguiente

instalar dive

--> wget https://github.com/wagoodman/dive/releases/download/v0.9.2/dive_0.9.2_linux_amd64.deb
sudo apt install ./dive_0.9.2_linux_amd64.deb

de esta forma ya podremos ejecutar la siguiente imagen

--> dive ubuntu:platzi (veo la info de la imagen con el programa dive)

La importancia de entender el sistema de capas consiste en la optimización de la construcción del contenedor para reducir espacio ya que cada comando 
en el dockerfile crea una capa extra de código en la imagen.

Agregando Capas
Con docker commit se crea una nueva imagen con una capa adicional que modifica la capa base.

Ejemplo: crear una nueva imagen a partir de la imagen de Ubuntu.

--> docker pull ubuntu

docker images
--> docker run -it cf0f3ca922e0 bin/bash

(modificar el contenedor: Ej apt-get install nmap)
-->docker commit deddd39fa163 ubuntu-nmap



*** USANDO DOCKER PARA DESARROLLAR APLICACIONES ***

Comandos:

--> git clone https://github.com/platzi/docker
--> docker build platziapp . (creo la imagen local)
--> docker image ls (listo las imagenes locales)
--> docker run --rm -p 3000:3000 platziapp (creo el contenedor y cuando se detenga se borra, lo publica el puerto 3000)
--> docker ps (veo los contenedores activos)

explicacion del archivo descargado

#imagen base node en la version 12
FROM node:12

#copiar todo lo que hay en la carpeta actual a la carpeta /usr/src/ en el contenedor
COPY [".", "/usr/src/"]

#establecer el directorio de trabajo cd /usr/src
WORKDIR /usr/src

#descargar las dependencias del proyecto
RUN npm install

#le dice al contenedor que este escuchando en este puerto
EXPOSE 3000

#correr el comando node index.js
CMD ["node", "index.js"]



*** APROVECHANDO EL CACHE DE CAPAS PARA ESTRUCTURAR CORRECTAMENTE TUS IMAGENES ***

La clave está en estructurar nuestro Dockerfile de manera de que primero se copien todas las dependencias 
y posteriormente nuestro código fuente, que es el mas suceptible a cambios.

Comandos:
--> docker build platziapp . (creo la imagen local)
--> docker run --rm -p 3000:3000 -v pathlocal/index.js:<pathcontenedor>/index.js platziapp 
(corro un contenedor y monto el archivo index.js para que se actualice dinámicamente con nodemon que está declarado en mi Dockerfile)

ó

Evitar escribir todo el path para montar el bind mount
docker run --rm -p 3000:3000 -v $(pwd)/index.js:/usr/src/index.js platziapp


Archivo Dockerfile

FROM node:14
#no se tengan en cuenta los siguientes archivos
COPY ["package.json", "package-lock.json", "/usr/src/"]

WORKDIR /usr/src

RUN npm install
#copiamos lo que esta en la ruta del contenedor
COPY [".", "/usr/src/"]

EXPOSE 3000
#estara monitoreando los cambos que se esten realizando en el archivo index
CMD ["npx", "nodemon", "index.js"]



*** DOCKER NETWORKING: COLABOACION ENTRE CONTENEDORES ***

