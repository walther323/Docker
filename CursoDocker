------------------------------------------------
------------------------------------------------
Curso Docker Platzi
------------------------------------------------
------------------------------------------------

Docker
  Estandar para desarrollar, distribuir y ejecutar aplicaciones a nivel productivo

Por que?
  compatibilidad del software en los ambientes de desarrollo y produccion
  genera confianza, desplegar en otros entornos
  

*** LAS TRES AREAS EN EL DESARROLLO DE SOFTWARE PROFESIONAL ***
  
  1. construir
  
    escribir codigo es una peque√±a parte
    los problemas complejos necesitan equipos
      --> entornos de desarrollo
      --> dependencias
      --> entonrno de ejecucion
      --> equivalenias con entorno productivo
      --> servicios externos
    
  2. distribuir
  
    tu codigo tiene que transformarse en un artefacto o varios que puedan ser transformados
    a donde tenga que ser ejecutados
      --> divergencia de repositorios
      --> divergencia de artefactos
      --> versionado
      
  3. ejecutar
  
    la maquina donde se escribe el softare siempre es distinta a la maquina donde se ejecuta de manera productiva
      --> compatibilidad con el entorno productivo
      --> dependencias
      --> disponibilidad de servicios externos
      --> recursos de hardware
 

Aportes de la clase

Resumen de la clase:

‚ÄúDocker te permite construir, distribuir y ejecutar cualquier aplicaci√≥n en cualquier lado.‚Äù

Problem√°ticas del desarrollo de software
1. Construir - Escribir c√≥digo en la m√°quina del desarrollador. (Compile, que no compile, arreglar el bug, compartir c√≥digo, etc. )

Problem√°tica:
  Entorno de desarrollo (paquetes)
  Dependencias (Frameworks, bibliotecas)
  Versiones de entornos de ejecuci√≥n (runtime, versi√≥n Node)
  Equivalencia de entornos de desarrollo (compartir el c√≥digo)
  Equivalencia con entornos productivos (pasar a producci√≥n)
  Servicios externos (integraci√≥n con otros servicios ejem: base de datos)
  
2. Distribuir - Llevar la aplicaci√≥n donde se va a desplegar (Transformarse en un artefacto)

Problem√°tica:
  Output de build heterogeo (m√∫ltiples compilaciones)
  Acceso a servidores productivos (No tenemos acceso al servidor)
  Ejecuci√≥n nativa vs virtualizada
  Entornos Serverless

3. Ejecutar - Implementar la soluci√≥n en el ambiente de producci√≥n (Subir a producci√≥n)
  El reto Hacer que funcione como deber√≠a funcionar

Problem√°tica:
  Dependencia de aplicaci√≥n (paquetes, runtime)
  Compatibilidad con el entorno productivo (sistema operativo poco amigable con la soluci√≥n)
  Disponibilidad de servicios externos (Acceso a los servicios externos)
  Recursos de hardware (Capacidad de ejecuci√≥n - Menos memoria, procesador m√°s debil)
      


***  VIRTUALIZACION ***

version virtual de algun recurso tecnologico como (...) hardware, un sistema operativo, un dispositivo de almacenamiento o recurso de red
  
  permite atacar en simulateno os tres problemas del desarrollo de software profesional

Maquinas virtuales

  Problemas de las VMs
  
    Peso
      --> en el orden de los GB repiten archivos comunes, inicio lento

    Costos de administracion
      --> necesita mantenimiento igual que cualquier otra computadora
      
    Multiples de formatos
      --> VDI, VMDK, VHD, raw entre otras
      
para solucionar el tema de las maquinas virtuales se crearon los Contenedores

  Objetivo
    el empleo de contenedores para contruir y desplegar software
      --> flexibles
      --> livianos
      --> portables
      --> Bajo acoplamiento
      --> Escalables
      --> Seguros
  
Aporte de la clase

Un contenedor la unidad logica mas importande de docker que permite encapsular las dependencias de un proyecto en un entorno aislado, 
y pas√°rsela a tus compa√±eros o colocarlo en un servidor para el despliegue de manera f√°cil.

¬°Alerta! Puedes ver a un contendor como una maquina virtual pero eso no significa que lo sea, una maquina virtual puede llegar a se muy similar debido a sus funcionalidades 
como el aislamiento de procesos.

Entonces‚Ä¶ ¬øcu√°l es el beneficio de usar contenedores en lugar de maquinas virtuales?

El mayor beneficio es que los contenedores de Docker est√°n en el nivel de los MB eso nos da ventajas en el consumo de recursos, ya que estos corren compartiendo el host del 
kernel de Linux, por otro lado las maquinas virtuales son un sistema operativo(O.S) con sus propias apps que corre sobre el tuyo usando virtualizacion y que consume muchos 
recursos en el nivel de los GB. Una mejor forma de ver esto es observando la arquitectura de los contendores y de las maquinas virtuales



*** PREPARANDO TU ENTORNO DE TRABAJO ***

pagina web --> docker.com
  Doccker desktop
  Docker Hub
  Play with Docker
  
para maquinas windows menores a 10
  --> https://github.com/docker/toolbox/releases
windows 10
  --> 
  
aportes de la clase

Puedes seguir las gu√≠as de instalaci√≥n de docker en linux dependiendo de tu distribuci√≥n.
  Cent OS: https://docs.docker.com/engine/install/centos/
  Debian: https://docs.docker.com/engine/install/debian/
  Fedora: https://docs.docker.com/engine/install/fedora/
  Ubuntu: https://docs.docker.com/engine/install/ubuntu/



*** PRIMEROS PASOS DE CONTENEDOR - HOLA MUNDO ***

--> comando
  docker run <nombre del contenedor a crear>
    --> ejemplo docker run hello-world

aportes de la clase

- Levantando contenedores
üîπ Arrancar un contenedor.

docker run <image_container>
Ejemplo:

docker run hello-world
üîπ Arrancar un contenedor asign√°ndole un nombre.

docker run --name <name_container> <image_container>
Ejemplo:

docker run --name contenedor_test ubuntu
üîπ Arrancar un contenedor con una terminal interactiva. Pas√°ndole una shell para acceder al contenedor.

docker run -it <image_container> <shell>
Ejemplo:

docker run -it ubuntu bash
üîπ Arrancar un contenedor. Mapeando un puerto del host a un puerto del contenedor.

puerto_host : puerto_contenedor
docker run -p <host_port>:<container_port> <image_container>
Ejemplo:

docker run -p 8080:80 nginx
Igual que el ejemplo anterior pero dej√°ndolo en segundo plano.

docker run -p 8080:80 -d nginx
üîπ Arrancar un contenedor. Que tras terminar su periodo de vida. Ser√° eliminado autom√°ticamente.

docker run --rm <image_container>
Ejemplo:

docker run -p 8080:80 -d --rm nginx
üîπ Arrancar un contenedor con un volume.

docker run -v <volume_name>:<mount_point>:<options> <image_container>
Ejemplo:

Volume -> test
Punto de montaje en el contenedor -> /apps
Opciones -> rw (Lectura y escritura)
docker run -v test:/apps:rw nginx
üîπ Arrancar un contenedor con un bind mount.

docker run -v <shared_folder>:<mount_point>:<options> <image_container>
Ejemplo:

Ruta del host a compartir -> /home/application
Punto de montaje en el contenedor -> /apps
Opciones -> ro (Solo lectura)
docker run -v /home/application:/apps:ro ubuntu
üîπ Arrancar un contenedor con tmpfs.

docker run \
--mount type=tmpfs,destination=<mount_point>,tmpfs-mode=<permisos>,tmpfs-size=<bytes_size> \
<image_container>
Ejemplo:

Punto de montaje en el contenedor -> /temporal
Permisos -> Todos los permisos solo para el propietario.
Tama√±o del FS -> 21474836480 bytes = 20G
docker run \
--mount type=tmpfs,destination=/temporal,tmpfs-mode=700,tmpfs-size=21474836480 \
nginx
- Listando contenedores
üîπ Lista de los contenedores activos.

docker ps
üîπ Lista de todos los contenedores activos e inactivos del sistema.

docker ps -a
üîπ Lista los ID de todos los contenedores.

docker ps -aq
- Debugging
üîπ Inspeccionar la data de un contenedor.

Por su ID:
docker inspect <id_container>
Por su nombre:
docker inspect <name_container>
Aplicando filtros. Por ejemplo buscando las variables de entorno:
docker inspect -f '{{ json .Config.Env }}' <name_container>
üîπ Ver los logs del contenedor.

docker logs <name_container>
- Eliminando contenedores
üîπ Eliminar un contenedor que no este arriba.

Se puede hacer tanto por nombre como por ID.
docker rm <name_container>
üîπ Eliminar un contenedor aunque este arriba. Forz√°ndolo.

Se puede hacer tanto por nombre como por ID.
docker rm -f <id_container>
üîπ Eliminar todos los contenedores que no esten arriba a la vez.

docker rm $(docker ps -aq)
   


*** CONCEPTO FUNDAMENTALES DE DOCKER - CONTENEDORES ***

Docker es una herramienta de codigo abierto que nos sirve para desarrollar, enviar y ejecutar
aplicaciones en contenedores

que son los contenedores?
  son unidades logicas computadas por un conjunto de procesos
  los contenedores surgieron con la union de varias tecnologias como
    namespaces
    cgroups
    chroot

Docker por dentro

mediante el cliente podremos enviar comandos al docker deamon para interactuar con los contenedors
  docker deamon recibe los comandos y envia ordenes a los contenedores para indicarles como y que deben ejecutar

contenedores
  ejecutan los proceso indicados por el docker deamon
  estos procesos viven en el contenedor y mueren con el contenedor, esto hace que se mantengan
  asilados de los proceso que se mantengan aislados de los procesos que corren en el sistma operativo del host

aunque puedes usar Docker tanto en windows como MacOs. este solo corre nativamente en Linux


Por que usar Docker?

  "en mi equipo la app corria correctamente"
  evita fallos gracias a que podras tener entornos de desarrollo y de produccion practicamente iguales
  
  "Evita problemas con las versiones"
  en cada contenedor podras correr lo que necesites
  
  "Distribuye y comparte facilmente"
  una de las grandes ventajas de los contenedores es su peque√±o tama√±o. imagina tener un Linuz en tan solo 5MB con Docker es posible
  

Que es un contenedor ?

  Es una agrupaci√≥n de procesos.
  Es una entidad l√≥gica, no tiene el limite estricto de las m√°quinas virtuales, emulaci√≥n del sistema operativo simulado por otra m√°s abajo.
  Ejecuta sus procesos de forma nativa.
  Los procesos que se ejecutan adentro de los contenedores ven su universo como el contenedor lo define, no pueden ver mas all√° del contenedor, a pesar de estar corriendo en una maquina m√°s grande.
  No tienen forma de consumir m√°s recursos que los que se les permite. Si esta restringido en memoria ram por ejemplo, es la √∫nica que pueden usar.
  A fines pr√°cticos los podemos imaginar c√≥mo maquinas virtuales, pero NO lo son. M√°quinas virtuales livianas.
  Docker corre de forma nativa solo en Linux.
  Sector del disco: Cuando un contenedor es ejecutado, el daemon de docker le dice, a partir de ac√° para arriba este disco es tuyo, pero no puedes subir mas arriba.
  Docker hace que los procesos adentro de un contenedor este aislados del resto del sistema, no le permite ver m√°s all√°.
  Cada contenedor tiene un ID √∫nico, tambi√©n tiene un nombre.



*** COMPRENDIENDO DOCKER ***

Comandos:

  $ docker run hello-world (corro el contenedor hello-world)
  $ docker ps (muestra los contenedores activos)
  $ docker ps -a (muestra todos los contenedores)
  $ docker inspect <containe ID> (muestra el detalle completo de un contenedor)
  $ docker inspect <name> (igual que el anterior pero invocado con el nombre)
  $ docker run ‚Äì-name hello-platzi hello-world (le asigno un nombre custom ‚Äúhello-platzi‚Äù)
  $ docker rename hello-platzi hola-platzy (cambio el nombre de hello-platzi a hola-platzi)
  $ docker rm <ID o nombre> (borro un contenedor)
  $ docker container prune (borro todos lo contenedores que esten parados)



*** EL MODO INTERACTIVO - CORRER UN LINUX UBUNTU CON DOCKER  ***

comando
--> docker run ubuntu
--> docker run -it ubuntu  (el comando it significa iterativo, podemos entrar a la maquina de ubuntu y navegar entre sus archivos)

Comandos:
$ docker run ubuntu (corre un ubuntu pero lo deja apagado)
$ docker ps -a (lista todos los contenedores)
$ docker -it ubuntu (lo corre y entro al shell de ubuntu)
-i: interactivo
-t: abre la consola
  --> cat /etc/lsb-release (veo la versi√≥n de Linux)


With an Existing container

1. start the container
    --> docker start id-container
2. execute interactively bash in the container
    --> docker exec -it id-container bash 



*** CICLO DE VIDA DE UN CONTENEDOR  ***

comando
  --> $ docker run --name alwaysup -d ubuntu tail -f /dev/null
  
  observaciones
    se pueden usar al final del tail -f las siguientes instrucciones para que no se apague el contenedor
      /dev/full
      /dev/zero
      /dev/random
      
  --> $ docker exec -it alwaysup bash
  
  --> $ docker inspect --format '{{.State.Pid}}' alwaysup
      --> 3744
      --> $ kill 3744
          bash: kill: (3744) - No such process (no corre en windows)
      
          Para detener procesos en windows usamos el siguiente comando
          --> $ docker stop alwaysup



***  EXPONIENDO CONTENEDORES ***

Comandos:

$ docker run -d --name proxy nginx (corro un nginx)
$ docker stop proxy (apaga el contenedor)
$ docker rm proxy (borro el contenedor)
$ docker rm -f <contenedor> (lo para y lo borra)

$ docker run -d --name proxy -p 8080:80 nginx (corro un nginx y expongo el puerto 80 del contenedor en el puerto 8080 de mi m√°quina)
  --> docker run -d --name [name] -p [HostPort/8080]:[ContainerPort/80] [imagen/nginx]

localhost:8080 (desde mi navegador compruebo que funcione)
$ docker logs proxy (veo los logs)
$ docker logs -f proxy (hago un follow del log)
$ docker logs --tail 10 -f proxy (veo y sigo solo las 10 √∫ltimas entradas del log)



*** BIND MOUNTS  ***

Todo lo que se ve en esta clase est√° relacionado con vol√∫menes y como ya se dijo en clases anteriores Docker es virtualizaci√≥n de sistemas encontramos 
tambi√©n vol√∫menes que son algo as√≠ como discos duros o datos que los contenedores pueden usar

Hay varios tipos de vol√∫menes

--> Container --> (bind mount)  --> filesystem 
              --> (Volume)      --> [docker area] 
              --> tmpfs mount   ----------------------> Memory

Para diferentes usos pero siempre se usan para persistir datos como por ejemplo imagina que est√°s haciendo una app que usa postgres sin importar 
la tecnolog√≠a que usas para la l√≥gica (node, python, php, java, c#) puedes tener muchas instancias de postgres en muchas versiones y los datos no se perder√°n 
a menos que los elimines

--> https://docs.docker.com/storage/volumes/

Para W10
usar√© este tutorial para lo que me comentaste sobre WSL2:
https://platzi.com/tutoriales/1650-prework/5895-aprende-a-instalar-wsl-2-de-la-manera-sencilla/
y luego har√© lo que me comentas üòÉ

Comandos:

$ mkdir dockerdata (creo un directorio en mi m√°quina)
$ docker run -d --name db mongo
$ docker ps (veo los contenedores activos)
$ docker exec -it db bash (entro al bash del contenedor)
$ mongo (me conecto a la BBDD)

    shows dbs (listo las BBDD)
    use platzi ( creo la BBDD platzi)
    db.users.insert({"nombre":"walther"}) (inserto un nuevo dato)
    db.users.find() (veo el dato que cargu√©)
    $ docker run -d --name db -v <path de mi maquina>:<path dentro del contenedor(/data/db mongo)> (corro un contenedor de mongo y creo un bind mount)



*** VOLUMENES  ***

Manera mas estandar en manejar la informacion de los dockers
Fueron una evolucion para manejar datos, 
mejora la seguridad de la informacion cuando se guarda los datos en disco
solo los volumenes pueden acceder a los datos creados desde esta opcion
por bind-mount cualquiera con acceso al disco podria manipular los datos

Comandos volumenes

--> docker volume ls (lista todos los volumenes creados)
--> docker volume create [nombre de la bd]
--> docker run -d --name db --mount src=dbdata,dst=/data/db mongo (ruta destino donde mongo db guarda su bd)



*** INSERTS Y EXTRAER ARCHIVOS DE UN CONTENEDOR  ***

Comandos:

$ touch prueba.txt (creo un archivo en mi m√°quina)
$ docker run -d --name copytest ubuntu tail -f /dev/null (corron un ubuntu y le agrego el tail para que quede activo)
$ docker exec -it copytest bash (entro al contenedor)
$ mkdir testing (creo un directorio en el contenedor)
$ docker cp prueba.txt copytest:/testing/test.txt (copio el archivo dentro del contenedor)
$ docker cp copytest:/testing localtesting (copio el directorio de un contenedor a mi m√°quina)
con "docker cp" no hace falta que el contenedor est√© corriendo

HOST

  Container   -->   Bind mount    --> Filesystem 
              ----------------------> [Docker Area]   
              ----- tmpts mount -----------------------> Memory

Host        --> Donde Docker esta instalado
Bind Mount  --> Guarda los archivos en la maquina local persistiendoy visualizando estos datos (No seguro)
Volumen     --> Guarda los archivos en el area de Docker donde Docker los administra (Seguro) 
TMPFS Mount --> Guarda los archivos temporales y persisten los datos en la memoria del contenedor, cuando muera sus datos mueren con el contenedor


Acerca de el comando tail
-------------------------
Por default, √©ste comando imprime las √∫ltimas 10 l√≠neas de un archivo en el sistema operativo GNU/Linux y luego termina.
al pasarle -f, indicamos que se ‚Äúvigilen‚Äù los cambios en el archivo que le pasemos.

Acerca de /dev/null

Se le conoce como una ‚Äúcaja negra‚Äù que no contiene ni hace nada.
para entender mejor el uso de √©ste fichero podemos analizar los siguientes casos:
Si ejecutamos el comando

- -> cat /dev/null

No se producir√° salida o mensaje

Por lo cual es normalmente utilizado para recibir archivos basura (descartables), o para vaciar archivos mediante redirecci√≥n:

  --> ls > /dev/null

Manda la lista de archivos de ls a el archivo /dev/null, con lo cual dicha lista desaparece.

Si ejecutamos la siguiente orden:

  --> cat /dev/null  > Archivo.Awk

Estar√≠amos borrando el contenido de Archivo.Awk, es decir, dej√°ndolo vac√≠o.

Como nota final, cabe aclarar que no es posible copiar o mover archivos hacia /dev/null

Pr√°ctica realizada:

Para crear un archivo en mi m√°quina:

  --> touch prueba.txt

Crear un contenedor llamado copytest, que corra ubuntu e iniciar un proceso que se mantenga activo:

  --> docker run -d --name copytest ubuntu tail -f /dev/null

Iniciar una conexi√≥n de terminal con el contenedor que est√° corriendo ubuntu

docker exec -it copytest bash

Creamos un directorio llamado testing en el contenedor de ubuntu

  --> mkdir testing

Comando docker para copiar un fichero o un directorio desde la m√°quina anfitri√≥n hacia el contenedor, copytest es el nombre del contenedor hacia el cual queremos copiar el archivo

  --> docker cp prueba.txt copytest:/testing/test.txt

Comando para ejecutar la acci√≥n inversa, es decir, copiar fichero o directorio desde el contenedor hacia la m√°quina anfitri√≥n.
donde localtesting ser√° el nombre de un nuevo directorio que se crear√° en la m√°quina anfitri√≥n dentro del directorio en el que nos encontremos al momento de haber ejecutado el siguiente comando:

  -->  docker cp copytest:/testing localtesting 

Nota: utilizando docker cp, no es necesario que el contenedor est√© corriendo



*** CONCEPTOS FUNDAMENTALES DE DOCKER: IMAGENES  ***


las imagenes son como Docker intenta solucionar el tema de cosntruccion y distribucion de software
plantillas o modles de las cuales docker crea contenedores
empaquetados para que docker pueda ejecutarse
  --> configuracion
  --> librerias
  --> archivos

Comandos:

  --> docker image ls (veo las im√°genes que tengo localmente)
  --> docker images -a (veo las imagenes instaladas)
  --> docker pull <image_name>:<tag_version>
      ejemplo:  docker pull ubuntu:20.04 (bajo la imagen de ubuntu con una versi√≥n espec√≠fica)
  
  
  
  *** CONTRUYENDO UNA IMAGEN PROPIA ***
  
 cada imagen es un conjunto de capas
 
  Comandos:

--> mkdir imagenes (creo un directorio en mi m√°quina)
--> cd imagenes (entro al directorio)
--> touch Dockerfile (creo un Dockerfile)
--> code . (abro code en el direcotrio en el que estoy)

##Contenido del Dockerfile##
FROM ubuntu:latest
RUN touch /ust/src/hola-platzi.txt (comando a ejecutar en tiempo de build)
##fin##

--> docker build -t ubuntu:platzi . (creo una imagen con el contexto de build <directorio>)
--> docker run -it ubuntu:platzi (corro el contenedor con la nueva imagen)
--> docker login (me logueo en docker hub)
--> docker tag ubuntu:platzi miusuario/ubuntu:platzy (cambio el tag para poder subirla a mi docker hub)
--> docker push miusuario/ubuntu:platzi (publico la imagen a mi docker hub)



*** EL SISTEMA DE CAPAS ***

Comandos:

--> docker history ubuntu:platzi (veo la info de como se construy√≥ cada capa)

el comando anterior no es muy comoda para revisar las configuraciones, para 
esto es la el comando siguiente

instalar dive

--> wget https://github.com/wagoodman/dive/releases/download/v0.9.2/dive_0.9.2_linux_amd64.deb
sudo apt install ./dive_0.9.2_linux_amd64.deb

de esta forma ya podremos ejecutar la siguiente imagen

--> dive ubuntu:platzi (veo la info de la imagen con el programa dive)

La importancia de entender el sistema de capas consiste en la optimizaci√≥n de la construcci√≥n del contenedor para reducir espacio ya que cada comando 
en el dockerfile crea una capa extra de c√≥digo en la imagen.

Agregando Capas
Con docker commit se crea una nueva imagen con una capa adicional que modifica la capa base.

Ejemplo: crear una nueva imagen a partir de la imagen de Ubuntu.

--> docker pull ubuntu

docker images
--> docker run -it cf0f3ca922e0 bin/bash

(modificar el contenedor: Ej apt-get install nmap)
-->docker commit deddd39fa163 ubuntu-nmap



*** USANDO DOCKER PARA DESARROLLAR APLICACIONES ***

Comandos:

--> git clone https://github.com/platzi/docker
--> docker build platziapp . (creo la imagen local)
--> docker image ls (listo las imagenes locales)
--> docker run --rm -p 3000:3000 platziapp (creo el contenedor y cuando se detenga se borra, lo publica el puerto 3000)
--> docker ps (veo los contenedores activos)

explicacion del archivo descargado

#imagen base node en la version 12
FROM node:12

#copiar todo lo que hay en la carpeta actual a la carpeta /usr/src/ en el contenedor
COPY [".", "/usr/src/"]

#establecer el directorio de trabajo cd /usr/src
WORKDIR /usr/src

#descargar las dependencias del proyecto
RUN npm install

#le dice al contenedor que este escuchando en este puerto
EXPOSE 3000

#correr el comando node index.js
CMD ["node", "index.js"]



*** APROVECHANDO EL CACHE DE CAPAS PARA ESTRUCTURAR CORRECTAMENTE TUS IMAGENES ***

La clave est√° en estructurar nuestro Dockerfile de manera de que primero se copien todas las dependencias 
y posteriormente nuestro c√≥digo fuente, que es el mas suceptible a cambios.

Comandos:
--> docker build platziapp . (creo la imagen local)
--> docker run --rm -p 3000:3000 -v pathlocal/index.js:<pathcontenedor>/index.js platziapp 
(corro un contenedor y monto el archivo index.js para que se actualice din√°micamente con nodemon que est√° declarado en mi Dockerfile)

√≥

Evitar escribir todo el path para montar el bind mount
docker run --rm -p 3000:3000 -v $(pwd)/index.js:/usr/src/index.js platziapp


Archivo Dockerfile

FROM node:14
#no se tengan en cuenta los siguientes archivos
COPY ["package.json", "package-lock.json", "/usr/src/"]

WORKDIR /usr/src

RUN npm install
#copiamos lo que esta en la ruta del contenedor
COPY [".", "/usr/src/"]

EXPOSE 3000
#npx nodemon stara monitoreando los cambos que se esten realizando en el archivo index
CMD ["npx", "nodemon", "index.js"]



*** DOCKER NETWORKING: COLABOACION ENTRE CONTENEDORES ***

Comandos:
--> docker network ls (listo las redes)
--> docker network create --atachable plazinet (creo la red)
--> docker inspect plazinet (veo toda la definici√≥n de la red creada)
--> docker run -d --name db mongo (creo el contenedor de la BBDD)
--> docker network connect plazinet db (conecto el contenedor ‚Äúdb‚Äù a la red ‚Äúplatzinet‚Äù)
--> docker run -d -name app -p 3000:3000 --env MONGO_URL=mondodb://db:27017/test platzi (corro el contenedor ‚Äúapp‚Äù y le paso una variable)
--> docker network connect plazinet app (conecto el contenedor ‚Äúapp‚Äù a la red ‚Äúplazinet‚Äù)

comandos citados previamente

--> docker network ls (listo las redes)
--> docker network create --attachable <name_red> (creo la red y permitimos que otros contenedores accedan a ella ‚Äúattachable‚Äù)
--> docker inspect <name_red> (veo toda la definici√≥n de la red creada)
--> docker run -d --name <name_container> mongo (creo el contenedor de la BD)
--> docker network connect <name_red> <name_container> (conecto la red ‚Äúname_red‚Äù al contenedor de la bd ‚Äúname_container‚Äù)
--> docker run -d --name <name_container> -p 3000:3000 --env MONGO_URL=mongodb://db:27017/test <name_image> (corro un contenedor nuevo ‚Äú<name_container> ‚Äù, le paso una variable de entorno ‚Äù- -env‚Äù y el nombre de la imagen a la que le quiero asignar este nuevo contenedor‚Äú<name_image>‚Äù)
--> docker network connect <name_red> <name_container> (conecto la red ‚Äú<name_red>‚Äù al contenedor que se asigno a la imagen‚Äú<name_container>‚Äù)



*** DOCKER COMPOSE: LA HERRAMIENTA TODO EN UNO ***

"describir de forma declarativa la arquitectura de servicios que nuestra aplicacione necesita,en un archivo donde declaramos lo que queremos que pase y 
docker por detras se encarga de ejecutar todos estos pasos que antes ejeuctabamos manualmente".


instalar docker-compose en Linux

1) sudo curl -L "https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
2) sudo chmod +x /usr/local/bin/docker-compose
3) docker-compose --version
    Resultado:  docker-compose version 1.27.4, build 1110ad01


estructura del archivo docker-compose.yml


Observacion:
el tabulado en compose es fundamental


//-- start file

//version del compose file
version: "3.8"

//los servicios que component la aplicacion
//multiples servicios - microservicios
//se detallan los contenedores que funcionaran
services:

  //los servicios que correran nuestra apliccion
  app:
  
    //todo contenedor nace de una imagen <image>
    image: platziapp
    
    //definir las variables de entorno
    environment:
      MONGO_URL: "mongodb://db:27017/test"
      
    //este contenedor va a depender de otro
    depends_on:
      - db
      
    //exponer el puerto del contenedor
    ports:
      - "3000:3000"
      
  //la base de datos que se conectara la aplicacion
  db:
    image: mongo

// end file


para ejecutar el archivo .YML vamos a la ruta donde esta el proyecto y ejecutamos el siguiente comando
--> docker compose up
el sistema creara la red, creara las imagenes y las conectara
el anterior comando levantara el servicio pero al darle CTRL + C terminara el proceso


para que se ejecute el contenedor por compose y quede corriendo por debajo escribimos
--> docker-compose up -d 

como bajar los servicios
--> docker-compose down



*** SUBCOMANDOS DE DOCKER COMPOSE ***

observacion:
los comandos de docker-compose solo funcionan si se ejecutan dentro de la carpeta que contiene la definicion de docker-compose.yml
si tratas de ejecutarlo desde afuera no lo reconocera


Comandos:

//contruir los servicios
--> docker-compose build
//levantar los servicios
--> docker-compose up
//levantar los servicios en dettach
--> docker-compose up -d
//bajar los servicios
--> docker-compose down (borro todo lo generado por docker compose)
//ver los logs de los contenedores
--> docker-compose logs
//ver los logs en modo follow
--> docker-compose logs -f
//ve los logs de un contenedor
--> docker-compose logs <service_name>
//correr un comando en un contenedor
--> docker-compose exec <service_name> <comand>
//correr un nuevo contenedor basado en un servicio
--> docker-compose run -rm <service_name> <comand>
//correr un nuevo contenedor basado en un servicio exponiendo un puerto
--> docker-compose run --rm --service-ports <service_name> <comand>


--> docker network ls (listo las redes)
--> docker network inspect docker_default (veo la definici√≥n de la red)
--> docker-compose logs (veo todos los logs)
--> docker-compose logs app (solo veo el log de ‚Äúapp‚Äù)
--> docker-compose logs -f app (hago un follow del log de app)
--> docker-compose exec app bash (entro al shell del contenedor app)
--> docker-compose ps (veo los contenedores generados por docker compose)
--> docker-compose down (borro todo lo generado por docker compose)


*** DOCKER COMPOSE COMO HERRAMIENTA DE DESARROLLO ***


archivo docker-compose.yml

//-------------- start file ------------------

version: "3.8"

services:
  app:
    build: .
    environment:
      MONGO_URL: "mongodb://db:27017/test"
    depends_on:
      - db
    ports:
      - "3000:3000"
    volumes: 
      - .:/usr/src
      - /usr/src/node_modules
    command: npx nodemon index.js
  db:
    image: mongo

//-------------- end file ------------------


archivo index.js

//-------------- start file ------------------

FROM node:14

COPY ["package.json", "package-lock.json", "/usr/src/"]

WORKDIR /usr/src

RUN npm install

COPY [".", "/usr/src/"]

EXPOSE 3000

CMD ["node", "index.js"]

//-------------- end file ------------------



*** COMPOSE EN EQUIPO: OVERRIDE ***

compose file y sirve para personalizar nuestro o hace peque√±os cambios en nuestro ambiente

docker-compose.override.yml es un archivo que se encarga de sobreescribir tu configuraci√≥n de docker-compose.yml , se puede usar para tener segura tu configuraci√≥n
y para no guardar los cambios en el repositorio de git.

Un equivalente podr√≠a ser los archivos de declaraci√≥n de variables de entorno, donde hay un archivo .env declarando su nombre y valor, 
y hay una copia .env.example con solo las variables sin valor. En .gitignore se declara que los cambios en .env no ser√°n guardados, pero mandamos el archivo 
de ejemplo al repositorio.

Comandos:
--> touch docker-compose.override.yml (creo el archivo override)
--> docker-compose up -d (crea los servicios/contenedores)
--> docker-compose exec app bash (entro al bash del contenedor app)
--> docker-compose ps (veo los contenedores del compose)
--> docker-compose up -d --scale app=2 (escalo dos instancias de app, previamente tengo que definir un rango de puertos en el archivo compose)
--> docker-compose down (borro todo lo creado con compose)


Para disponer de m√∫ltiples contenedores (escalar) de un mismo servicio, se requiere habilitar un rango de puertos en el host (m√°quina donde corre Docker), 
se realiza mediante la instrucci√≥n puerto [PUERTO-PUERTO]. Para escalar un servicio se puede usar el flag ‚Äú‚Äìscale‚Äù en el comando up:

en el archivo docker-compose.yml en la especificacion de los puertos poner
  3000-3001:3000
  
  
  --> docker-compose up -d --scale [nameService]=[numberContainers]
  ejemplo: docker-compose up -d --scale app=2
  resultado: creado dos docker 
  


*** ADMINISTRANDO TU AMBIENTE DE DOCKER ***

Comandos:
--> docker ps -a (veo todos los contenedores de mi m√°quina)
--> docker container prune (borra todos los contenedores inactivos)
--> docker rm -f $(docker ps -aq) (borra todos los contenedores que est√©n corriendo o apagados)
--> docker network ls (lista todas las redes)
--> docker volume ls (lista todos los volumes)
--> docker image ls (lista todas las im√°genes)
--> docker system prune (borra todo lo que no se est√© usando)
--> docker run -d --name app --memory 1g platziapp (limito el uso de memoria)
--> docker stats (veo cuantos recursos consume docker en mi sistema)
--> docker inspect app (puedo ver si el proceso muere por falta de recursos)

#Remove All
--> sudo docker rm -vf $(sudo docker ps -a -q)
--> sudo docker rmi -f $(sudo docker images -a -q)
--> sudo docker system prune -f
--> sudo docker volume prune -f

# Remove # Remove volumens and images
--> docker-compose -f production.yml down --volumes --rmi all

# Remove volumens and images
--> docker-compose -f production.yml down --volumes --rmi all

# Remove Migrations
--> sudo find . -path "*/migrations/*.py" -not-name "__init__.py" -delete
--> sudo find . -path "*/migrations/*.pyc" -delete

# Eliminar todos los contenedores que no estan corriendo o apagados
--> docker container prune

# Eliminar las redes que no estamos usando
--> docker network prune

# Limito el uso de memoria
--> docker run -d --name app --memory 1g platziapp

# Ver cuantos recursos consume docker en mi sistema
--> docker stats

# Ver si el proceso muere por falta de recursos
--> docker inspect app

Para borrar imagnes no utilizadas:
--> docker imagen prune

Para borrar todas las imagenes existentes:
--> docker image rm -f $(docker image ls -qa)



*** DETENIENDO CONTENEDORES CORRECTAMENTE: SHELL VS EXEC ***

--> docker stop √≥ kill <looper>

Observacion
Exited (137) 22 minutes ago
  mensajes de salidas mayor a 128 es un aviso que el proceso no finalizo de la mejor manera
  si le restamos a 137 - 128 da 9 --> el programa hizo un kill 9 --> mato el proceso
  
  
Comandos:
--> docker build -t loop . (construyo la imagen)
--> docker run -d --name looper loop (corro el contenedor)
--> docker stop looper (le env√≠a la se√±al SIGTERM al contenedor)
--> docker ps -l (muestra el ps del √∫ltimo proceso)
--> docker kill looper (le env√≠a la se√±al SIGKILL al contenedor)
--> docker exec looper ps -ef (veo los procesos del contenedor)


Shell: Ejecuta el proceso como hijo del shell

FROM ubuntu:trusty
COPY ["loop.sh", "/"]
CMD /loop.sh

Exec: Ejecuta el comando como principal

FROM ubuntu:trusty
COPY ["loop.sh", "/"]
CMD ["/loop.sh"]

tener en cuenta

En windows, si estan usando Visual studio Code, y al momento de ejecutar:
  --> docker run -d --name looper loop
si no se queda ejecutando el script, puede ser por los codigos de control, que por defecto en 
visual studio estan en CRLF y debe ser LF para que funcione en windows



*** CONTENEDORES EJECUTABLES: ENTRYPOINT VS CMD ***


Comandos:
--> docker buils -t ping . (construyo la imagen)
--> docker run --name pinger ping <hostname> (ahora le puedo pasar un par√°metro, previamente tengo que agregar el ENTRYPOINT en el Dockerfile)

>> cd avanzado/ping

FROM ubuntu:trusty
CMD ["/bin/ping", "-c", "3","localhost"]

El parametro que enviamos por linea de comandos sobreescribe
"/bin/ping", "-c", "3","localhost"

FROM ubuntu:trusty
ENTRYPOINT [ "/bin/ping", "-c", "3"]
CMD ["localhost"]

De esta manera solo se sobreescribe localhost

-------------------------------------
otro aporte
-------------------------------------

cd avanzado/ping

--> nano Dockerfile 

#######Dockerfile#######
FROM ubuntu:trusty
CMD ["/bin/ping", "-c", "3", "localhost"]
########################

--> docker build -t ping .
--> docker run --name pinger ping

‚Äì Como hacemos para tener un contenedor ping, acepte parametros por linea de comando y si no recibe algo, haga algo.

hostname

--> docker run --name pinger ping hostname
--> nano Dockerfile 

#######Dockerfile#######
FROM ubuntu:trusty
ENTRYPOINT ["/bin/ping", "-c", "3"]
CMD ["localhost"]
########################

--> docker build -t ping .
--> docker run --name pinger ping
--> docker rm pinger
--> docker run --name pinger google.com



*** EL CONTEXTO BUILD ***

el concepto de build, cada vez que hacems un build a una image
docker monta al filesystem temporal los archivos que va a usar para desplegar el sistema

si tengo esto disponible, es un problema, para optimizarlo se realiza lo sgte


>> cd platzi/docker

--> nano Dockerfile

########Dockerfile########
FROM node:14
COPY [".", "/usr/src/"]
WORKDIR /usr/src
RUN npm install
EXPOSE 3000
CMD ["node", "index.js"]
##########################

--> docker build -t prueba .
--> npm install

‚Äì Archivo .dockerignore para que agrege archivos carpetas que no quieres que se considere en el build

nano .dockerignore

########.dockerignore########
*.log
.dockerignore
.git
.gitignore
build/*
Dockerfile
node_modules
npm-debug.log*
README.md
##########################

--> docker build -t prueba .
--> docker run -d --rm --name app prueba
--> docker exec -it app bash

# ls -lac



*** MULTI-STAGE BUILD ***

en el proyecto docker existe una carpeta con los sgtes archivos
  development.Dockerfile
  production.Dockerfile

Cuando no queres que codigo de desarrollo este en la imagen, unicamente queremos que esten archivos de produccion estos pueden ser binarios de ejecucion o en 
caso de nodejs (index.js, node_modules, package.json y package-lock.json)

--> nano development.Dockerfile

############development.Dockerfile############
FROM node:12
COPY ["package.json", "package-lock.json", "/usr/src/"]
WORKDIR /usr/src
RUN npm install
COPY [".", "/usr/src/"]
EXPOSE 3000
CMD ["npx", "nodemon", "index.js"]
################################################

--> nano build/production.Dockerfile

############production.Dockerfile############
FROM node:12 as builder
COPY ["package.json", "package-lock.json", "/usr/src/"]
WORKDIR /usr/src
RUN npm install --only=production
COPY [".", "/usr/src/"]
RUN npm install --only=development
RUN npm run test

# Productive image
FROM node:12
COPY ["package.json", "package-lock.json", "/usr/src/"]
WORKDIR /usr/src
RUN npm install --only=production
COPY --from=builder ["/usr/src/index.js", "/usr/src/"]
EXPOSE 3000
CMD ["node", "index.js"]
################################################

--> docker build -t prodapp -f build/production.Dockerfile . (por default se va al dockerfile de la raiz, se debe especificar cual se quiere cargar)
--> docker image ls
--> docker run -d --name prod prodapp 
--> docker exec -it prod bash

# ls -lac
# docker ps
# exit

‚Äì Experimentamos editando el archivo test/test.js para que falle, comprobamos que fallara el layer falla y se detiene el build

docker build -t prodapp -f build/production.Dockerfile .



*** DOCKER IN DOCKER ***


Comandos:
--> docker run -it --rm -v /var/run/docker.sock:/var/run/docker.sock docker:19.03.12
--> docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock -v $(wich docker):/bin/docker wagoodman/dive:latest prodapp


Si queremos tener docker dentro de un contenedor, mas llamado docker-in-docker. Compartiendo el socket de nuestro local a nuestro contenedor que tendra docker.

--> docker run -it --rm -v /var/run/docker.sock:/var/run/docker.sock docker:19.03.12 
# docker ps
# docker run -d --name app prodapp

‚Äì Comprobamos desde otra terminal
--> docker ps

‚Äì Correr dive siendo un contenedor que explora el estado de docker.
--> docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/bin/docker wagoodman/dive:latest prodapp



------- cierre del curso -------

